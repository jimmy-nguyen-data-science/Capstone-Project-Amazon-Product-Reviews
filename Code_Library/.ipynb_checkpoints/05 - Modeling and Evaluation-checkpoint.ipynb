{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b73a15f",
   "metadata": {},
   "source": [
    "# Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48e8a9cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T06:34:20.901614Z",
     "start_time": "2022-08-01T06:34:18.929934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd # pandas package\n",
    "pd.options.display.max_columns = 40\n",
    "\n",
    "import numpy as np # numpy package\n",
    "\n",
    "# matplotlib packages\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 6.0)\n",
    "\n",
    "import seaborn as sns # seaborn package\n",
    "# dictionary package\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import warnings  # warnings package\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "# plotly packages\n",
    "from chart_studio import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import iplot\n",
    "\n",
    "# cufflink packages\n",
    "import cufflinks\n",
    "cufflinks.go_offline()\n",
    "cufflinks.set_config_file(world_readable=True, theme='pearl')\n",
    "\n",
    "# interactive shell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'last_expr'\n",
    "\n",
    "from pathlib import Path # path package\n",
    "import re #regex package\n",
    "from textblob import TextBlob #import textblob package\n",
    "\n",
    "# word cloud\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "# nltk packages\n",
    "import nltk\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "# stop words\n",
    "from nltk.corpus import stopwords\n",
    "sw = set(stopwords.words(\"english\"))\n",
    "\n",
    "# punctuation\n",
    "from string import punctuation\n",
    "\n",
    "# detokenizer \n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "# sklearn packages\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#imblean packages for undersampling/oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import NearMiss \n",
    "from imblearn.under_sampling import OneSidedSelection\n",
    "\n",
    "# pickle package\n",
    "import _pickle as cPickle\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615720c8",
   "metadata": {},
   "source": [
    "# Loading Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9eeff74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T06:34:20.956067Z",
     "start_time": "2022-08-01T06:34:20.904813Z"
    }
   },
   "outputs": [],
   "source": [
    "## Load tfidf model for new data later on\n",
    "tfidf = joblib.load('tfidf.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ccae1a",
   "metadata": {},
   "source": [
    "## SMOTE+ENN Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8960d60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T06:34:21.008516Z",
     "start_time": "2022-08-01T06:34:20.962813Z"
    }
   },
   "outputs": [],
   "source": [
    "# SMOTE+ENN Training Data - X variables\n",
    "with open(Path(r\"../Data/Preparation for Modeling Data/Binary Classification/X_train_smote.pickle\"), \"rb\") as input_file:\n",
    "    X_train_smote = cPickle.load(input_file)\n",
    "    \n",
    "# SMOTE+ENN Training Data - Target Variable Y\n",
    "with open(Path(r\"../Data/Preparation for Modeling Data/Binary Classification/Y_train_smote.pickle\"), \"rb\") as input_file:\n",
    "    Y_train_smote = cPickle.load(input_file).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4358b8d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T05:40:47.240265Z",
     "start_time": "2022-07-27T05:40:47.227759Z"
    }
   },
   "source": [
    "## Near-miss Sampling Training Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bad52ab2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T06:34:21.028622Z",
     "start_time": "2022-08-01T06:34:21.011477Z"
    }
   },
   "outputs": [],
   "source": [
    "# Near-miss Training Data - X variables\n",
    "with open(Path(r\"../Data/Preparation for Modeling Data/Binary Classification/X_train_near.pickle\"), \"rb\") as input_file:\n",
    "    X_train_near = cPickle.load(input_file)\n",
    "    \n",
    "# Near-miss Training Data - Target Variable Y\n",
    "with open(Path(r\"../Data/Preparation for Modeling Data/Binary Classification/Y_train_near.pickle\"), \"rb\") as input_file:\n",
    "    Y_train_near = cPickle.load(input_file).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccf31e5",
   "metadata": {},
   "source": [
    "## One-sided Selection Sampling Training Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53940e0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T06:34:21.054817Z",
     "start_time": "2022-08-01T06:34:21.031291Z"
    }
   },
   "outputs": [],
   "source": [
    "# One-sided Selection Training Data - X variables\n",
    "with open(Path(r\"../Data/Preparation for Modeling Data/Binary Classification/X_train_oss.pickle\"), \"rb\") as input_file:\n",
    "    X_train_oss = cPickle.load(input_file)\n",
    "    \n",
    "# One-sided Selection Training Data - Target Variable Y\n",
    "with open(Path(r\"../Data/Preparation for Modeling Data/Binary Classification/Y_train_oss.pickle\"), \"rb\") as input_file:\n",
    "    Y_train_oss = cPickle.load(input_file).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130a74b5",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40d17db4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T06:34:21.073999Z",
     "start_time": "2022-08-01T06:34:21.057477Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test Data - X variables\n",
    "with open(Path(r\"../Data/Preparation for Modeling Data/Binary Classification/X_test.pickle\"), \"rb\") as input_file:\n",
    "    X_test = cPickle.load(input_file)\n",
    "    \n",
    "# Test Data - Target Variable Y\n",
    "with open(Path(r\"../Data/Preparation for Modeling Data/Binary Classification/Y_test.pickle\"), \"rb\") as input_file:\n",
    "    Y_test = cPickle.load(input_file).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97f1d28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T05:46:56.103458Z",
     "start_time": "2022-07-27T05:46:56.100469Z"
    }
   },
   "source": [
    "# Baseline Model - Dummy Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180e57e4",
   "metadata": {},
   "source": [
    "## Dummy Classifier with SMOTE+ENN Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17cf0551",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T06:34:21.171652Z",
     "start_time": "2022-08-01T06:34:21.076677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score with SMOTE+ENN Training Data  0.111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.11      1.00      0.20       375\n",
      "    Positive       0.00      0.00      0.00      3013\n",
      "\n",
      "    accuracy                           0.11      3388\n",
      "   macro avg       0.06      0.50      0.10      3388\n",
      "weighted avg       0.01      0.11      0.02      3388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Baseline Model - Dummy Classifier\n",
    "clf = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "# Fit to SMOTE+ENN training data\n",
    "clf.fit(X_train_smote, Y_train_smote)\n",
    "\n",
    "# Make predictions on original unsampled test data\n",
    "Y_pred_smote_baseline = clf.predict(X_test)\n",
    "\n",
    "# Print out Performance scores\n",
    "print ('Accuracy Score with SMOTE+ENN Training Data ', round(accuracy_score(Y_test, Y_pred_smote_baseline),3))\n",
    "print(classification_report(Y_test, Y_pred_smote_baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdf468e",
   "metadata": {},
   "source": [
    "## Dummy Classifier with Near-miss Sampling Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ed10aaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T06:34:21.266119Z",
     "start_time": "2022-08-01T06:34:21.174253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score with near-miss sampling Training Data  0.111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.11      1.00      0.20       375\n",
      "    Positive       0.00      0.00      0.00      3013\n",
      "\n",
      "    accuracy                           0.11      3388\n",
      "   macro avg       0.06      0.50      0.10      3388\n",
      "weighted avg       0.01      0.11      0.02      3388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Baseline Model - Dummy Classifier\n",
    "clf = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "# Fit to Near-miss sampling training data\n",
    "clf.fit(X_train_near, Y_train_near)\n",
    "\n",
    "# Make predictions on original unsampled test data\n",
    "Y_pred_near_baseline = clf.predict(X_test)\n",
    "\n",
    "# Print out Performance scores\n",
    "print ('Accuracy Score with near-miss sampling Training Data ', round(accuracy_score(Y_test, Y_pred_near_baseline),3))\n",
    "print(classification_report(Y_test, Y_pred_near_baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a298be46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T06:10:03.328190Z",
     "start_time": "2022-07-27T06:10:03.324833Z"
    }
   },
   "source": [
    "## Dummy Classifier with One-sided Selection Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94bbce82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T06:34:21.365243Z",
     "start_time": "2022-08-01T06:34:21.269638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score with one-sided selection sampling Training Data  0.889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00       375\n",
      "    Positive       0.89      1.00      0.94      3013\n",
      "\n",
      "    accuracy                           0.89      3388\n",
      "   macro avg       0.44      0.50      0.47      3388\n",
      "weighted avg       0.79      0.89      0.84      3388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Baseline Model - Dummy Classifier\n",
    "clf = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "# Fit to One-Sided Selection sampling training data\n",
    "clf.fit(X_train_oss, Y_train_oss)\n",
    "\n",
    "# Make predictions on original unsampled test data\n",
    "Y_pred_oss_baseline = clf.predict(X_test)\n",
    "\n",
    "# Print out Performance scores\n",
    "print ('Accuracy Score with one-sided selection sampling Training Data ', \n",
    "       round(accuracy_score(Y_test, Y_pred_oss_baseline),3))\n",
    "print(classification_report(Y_test, Y_pred_oss_baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369e1105",
   "metadata": {},
   "source": [
    "# SVM Classifier - Hyperparameter Tuning\n",
    "\n",
    "- Hyper-parameter tuning on  Training SMOTE+ENN Data\n",
    "- Hyper-parameter tuning on  Training Near-miss Sampling Data\n",
    "- Hyper-parameter tuning on  Training One-sided Selection Sampling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfcd13f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T06:34:21.372840Z",
     "start_time": "2022-08-01T06:34:21.368336Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add parameters in pipeline\n",
    "training_pipeline = Pipeline(\n",
    "steps=[\n",
    "('model', LinearSVC(random_state=42, tol=1e-5))])\n",
    "grid_param = [{\n",
    "'model__penalty': ['l1', 'l2'],\n",
    "'model__loss': ['hinge'],\n",
    "'model__max_iter': [10000]\n",
    "}, {\n",
    "'model__C': [1, 10],\n",
    "'model__tol': [1e-2, 1e-3]\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723c1f64",
   "metadata": {},
   "source": [
    "## SVM Classifier - Training on SMOTE+ENN Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "241d2e15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T06:34:24.330129Z",
     "start_time": "2022-08-01T06:34:21.376040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha parameter identified by grid search for SMOTE+ENN Data  {'model__C': 10, 'model__tol': 0.01}\n",
      "Best result identified by grid search for SMOTE+ENN Data 0.9883390270644583\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.988339</td>\n",
       "      <td>{'model__C': 10, 'model__tol': 0.01}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.988339</td>\n",
       "      <td>{'model__C': 10, 'model__tol': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.987347</td>\n",
       "      <td>{'model__C': 1, 'model__tol': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.987285</td>\n",
       "      <td>{'model__C': 1, 'model__tol': 0.01}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.985052</td>\n",
       "      <td>{'model__loss': 'hinge', 'model__max_iter': 10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score  \\\n",
       "4                1         0.988339   \n",
       "5                1         0.988339   \n",
       "3                3         0.987347   \n",
       "2                4         0.987285   \n",
       "1                5         0.985052   \n",
       "\n",
       "                                              params  \n",
       "4               {'model__C': 10, 'model__tol': 0.01}  \n",
       "5              {'model__C': 10, 'model__tol': 0.001}  \n",
       "3               {'model__C': 1, 'model__tol': 0.001}  \n",
       "2                {'model__C': 1, 'model__tol': 0.01}  \n",
       "1  {'model__loss': 'hinge', 'model__max_iter': 10...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid search to find best parameters\n",
    "gridSearchProcessor = GridSearchCV(estimator=training_pipeline,\n",
    "param_grid=grid_param, cv=5, n_jobs = -1)\n",
    "\n",
    "# SMOTE+ENN data\n",
    "gridSearchProcessor.fit(X_train_smote, Y_train_smote)\n",
    "\n",
    "# best parameters for SMOTE+ENN Data\n",
    "smote_best_params = gridSearchProcessor.best_params_\n",
    "\n",
    "# best model for SMOTE+ENN Data\n",
    "smote_best_model = gridSearchProcessor.best_estimator_\n",
    "\n",
    "# print out best parameters for SMOTE+ENN Data\n",
    "print(\"Best alpha parameter identified by grid search for SMOTE+ENN Data \", smote_best_params)\n",
    "smote_best_result = gridSearchProcessor.best_score_\n",
    "print(\"Best result identified by grid search for SMOTE+ENN Data\", smote_best_result)\n",
    "\n",
    "\n",
    "# see other parameter results\n",
    "gridsearch_results = pd.DataFrame(gridSearchProcessor.cv_results_)\n",
    "gridsearch_results[['rank_test_score', 'mean_test_score',\n",
    "'params']].sort_values(by=['rank_test_score'])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db5183fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T06:34:24.442538Z",
     "start_time": "2022-08-01T06:34:24.335253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for SMOTE+ENN Data  0.7550177095631642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.30      0.92      0.45       375\n",
      "    Positive       0.99      0.73      0.84      3013\n",
      "\n",
      "    accuracy                           0.76      3388\n",
      "   macro avg       0.64      0.83      0.65      3388\n",
      "weighted avg       0.91      0.76      0.80      3388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "Y_pred_smote = smote_best_model.predict(X_test)\n",
    "print('Accuracy Score for SMOTE+ENN Data ', accuracy_score(Y_test, Y_pred_smote))\n",
    "print(classification_report(Y_test, Y_pred_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342379d5",
   "metadata": {},
   "source": [
    "## SVM Classifier - Training on Near-miss Sampling Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "467da537",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T06:34:24.726886Z",
     "start_time": "2022-08-01T06:34:24.445085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha parameter identified by grid search for Near-miss Sampling Data  {'model__loss': 'hinge', 'model__max_iter': 10000, 'model__penalty': 'l2'}\n",
      "Best result identified by grid search for Near-miss Sampling Data 0.8761602671118531\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.876160</td>\n",
       "      <td>{'model__loss': 'hinge', 'model__max_iter': 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.873492</td>\n",
       "      <td>{'model__C': 1, 'model__tol': 0.01}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.873492</td>\n",
       "      <td>{'model__C': 1, 'model__tol': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.856471</td>\n",
       "      <td>{'model__C': 10, 'model__tol': 0.01}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.856137</td>\n",
       "      <td>{'model__C': 10, 'model__tol': 0.001}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score  \\\n",
       "1                1         0.876160   \n",
       "2                2         0.873492   \n",
       "3                2         0.873492   \n",
       "4                4         0.856471   \n",
       "5                5         0.856137   \n",
       "\n",
       "                                              params  \n",
       "1  {'model__loss': 'hinge', 'model__max_iter': 10...  \n",
       "2                {'model__C': 1, 'model__tol': 0.01}  \n",
       "3               {'model__C': 1, 'model__tol': 0.001}  \n",
       "4               {'model__C': 10, 'model__tol': 0.01}  \n",
       "5              {'model__C': 10, 'model__tol': 0.001}  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid search to find best parameters\n",
    "gridSearchProcessor = GridSearchCV(estimator=training_pipeline,\n",
    "param_grid=grid_param, cv=5, n_jobs = -1)\n",
    "\n",
    "# Near-miss sampling data\n",
    "gridSearchProcessor.fit(X_train_near, Y_train_near)\n",
    "\n",
    "# best parameters for Near-miss Sampling Data\n",
    "near_best_params = gridSearchProcessor.best_params_\n",
    "\n",
    "# best model for Near-miss Sampling Data\n",
    "near_best_model = gridSearchProcessor.best_estimator_\n",
    "\n",
    "# print out best parameters for Near-miss Sampling Data\n",
    "print(\"Best alpha parameter identified by grid search for Near-miss Sampling Data \", near_best_params)\n",
    "near_best_result = gridSearchProcessor.best_score_\n",
    "print(\"Best result identified by grid search for Near-miss Sampling Data\", near_best_result)\n",
    "\n",
    "\n",
    "# see other parameter results\n",
    "gridsearch_results = pd.DataFrame(gridSearchProcessor.cv_results_)\n",
    "gridsearch_results[['rank_test_score', 'mean_test_score',\n",
    "'params']].sort_values(by=['rank_test_score'])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba1cf87c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T06:34:24.831732Z",
     "start_time": "2022-08-01T06:34:24.729862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for Near-miss Sampling Data  0.7795159386068476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.32      0.91      0.48       375\n",
      "    Positive       0.99      0.76      0.86      3013\n",
      "\n",
      "    accuracy                           0.78      3388\n",
      "   macro avg       0.65      0.84      0.67      3388\n",
      "weighted avg       0.91      0.78      0.82      3388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "Y_pred_near = near_best_model.predict(X_test)\n",
    "print('Accuracy Score for Near-miss Sampling Data ', accuracy_score(Y_test, Y_pred_near))\n",
    "print(classification_report(Y_test, Y_pred_near))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6c9633",
   "metadata": {},
   "source": [
    "## SVM Classifier - Training on One-sided Selection Sampling Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57866875",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T06:34:25.793066Z",
     "start_time": "2022-08-01T06:34:24.834340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha parameter identified by grid search for One-sided selection Sampling Data  {'model__loss': 'hinge', 'model__max_iter': 10000, 'model__penalty': 'l2'}\n",
      "Best result identified by grid search for One-sided selection Sampling Data 0.927260205318891\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.927260</td>\n",
       "      <td>{'model__loss': 'hinge', 'model__max_iter': 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.926181</td>\n",
       "      <td>{'model__C': 1, 'model__tol': 0.01}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.926181</td>\n",
       "      <td>{'model__C': 1, 'model__tol': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.915931</td>\n",
       "      <td>{'model__C': 10, 'model__tol': 0.01}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>0.915931</td>\n",
       "      <td>{'model__C': 10, 'model__tol': 0.001}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score  \\\n",
       "1                1         0.927260   \n",
       "2                2         0.926181   \n",
       "3                2         0.926181   \n",
       "4                4         0.915931   \n",
       "5                4         0.915931   \n",
       "\n",
       "                                              params  \n",
       "1  {'model__loss': 'hinge', 'model__max_iter': 10...  \n",
       "2                {'model__C': 1, 'model__tol': 0.01}  \n",
       "3               {'model__C': 1, 'model__tol': 0.001}  \n",
       "4               {'model__C': 10, 'model__tol': 0.01}  \n",
       "5              {'model__C': 10, 'model__tol': 0.001}  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid search to find best parameters\n",
    "gridSearchProcessor = GridSearchCV(estimator=training_pipeline,\n",
    "param_grid=grid_param, cv=5, n_jobs = -1)\n",
    "\n",
    "# One-sided selection sampling data\n",
    "gridSearchProcessor.fit(X_train_oss, Y_train_oss)\n",
    "\n",
    "# best parameters for One-sided selection Sampling Data\n",
    "oss_best_params = gridSearchProcessor.best_params_\n",
    "\n",
    "# best model for One-sided selection Sampling Data\n",
    "oss_best_model = gridSearchProcessor.best_estimator_\n",
    "\n",
    "# print out best parameters for One-sided selection Sampling Data\n",
    "print(\"Best alpha parameter identified by grid search for One-sided selection Sampling Data \", oss_best_params)\n",
    "oss_best_result = gridSearchProcessor.best_score_\n",
    "print(\"Best result identified by grid search for One-sided selection Sampling Data\", oss_best_result)\n",
    "\n",
    "\n",
    "# see other parameter results\n",
    "gridsearch_results = pd.DataFrame(gridSearchProcessor.cv_results_)\n",
    "gridsearch_results[['rank_test_score', 'mean_test_score',\n",
    "'params']].sort_values(by=['rank_test_score'])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af23524a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T06:34:25.906352Z",
     "start_time": "2022-08-01T06:34:25.796350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for One-sided selection Sampling Data  0.9468713105076741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.82      0.66      0.73       375\n",
      "    Positive       0.96      0.98      0.97      3013\n",
      "\n",
      "    accuracy                           0.95      3388\n",
      "   macro avg       0.89      0.82      0.85      3388\n",
      "weighted avg       0.94      0.95      0.94      3388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "Y_pred_oss = oss_best_model.predict(X_test)\n",
    "print('Accuracy Score for One-sided selection Sampling Data ', accuracy_score(Y_test, Y_pred_oss))\n",
    "print(classification_report(Y_test, Y_pred_oss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1096aa93",
   "metadata": {},
   "source": [
    "# Random Forest Classifier - Hyperparameter Tuning\n",
    "\n",
    "- Hyper-parameter tuning on  Training SMOTE+ENN Data\n",
    "- Hyper-parameter tuning on  Training Near-miss Sampling Data\n",
    "- Hyper-parameter tuning on  Training One-sided Selection Sampling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71de6917",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T06:34:25.916595Z",
     "start_time": "2022-08-01T06:34:25.908825Z"
    }
   },
   "outputs": [],
   "source": [
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 50, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Rf model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "random_grid = {'n_estimators': [100,300,500],\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe79c3dd",
   "metadata": {},
   "source": [
    "## RF Classifier - Training on SMOTE+ENN Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93c6c6d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T06:48:54.873221Z",
     "start_time": "2022-08-01T06:34:25.921264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha parameter identified by grid search for SMOTE+ENN Data  {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None, 'bootstrap': False}\n",
      "Best result identified by grid search for SMOTE+ENN Data 0.9937352685770996\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>0.993735</td>\n",
       "      <td>{'n_estimators': 300, 'min_samples_split': 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2</td>\n",
       "      <td>0.992991</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 10,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0.992867</td>\n",
       "      <td>{'n_estimators': 300, 'min_samples_split': 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>0.992061</td>\n",
       "      <td>{'n_estimators': 500, 'min_samples_split': 10,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>5</td>\n",
       "      <td>0.991440</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 10,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score  mean_test_score  \\\n",
       "58                1         0.993735   \n",
       "65                2         0.992991   \n",
       "9                 3         0.992867   \n",
       "7                 4         0.992061   \n",
       "91                5         0.991440   \n",
       "\n",
       "                                               params  \n",
       "58  {'n_estimators': 300, 'min_samples_split': 2, ...  \n",
       "65  {'n_estimators': 100, 'min_samples_split': 10,...  \n",
       "9   {'n_estimators': 300, 'min_samples_split': 2, ...  \n",
       "7   {'n_estimators': 500, 'min_samples_split': 10,...  \n",
       "91  {'n_estimators': 100, 'min_samples_split': 10,...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random search to find best parameters\n",
    "rf_gridSearchProcessor = RandomizedSearchCV(estimator=rf,\\\n",
    "                                            param_distributions=random_grid, \n",
    "                                            cv=3, n_jobs = -1,\n",
    "                                            n_iter = 100)\n",
    "\n",
    "# SMOTE+ENN data\n",
    "rf_gridSearchProcessor.fit(X_train_smote, Y_train_smote)\n",
    "\n",
    "# best parameters for SMOTE+ENN Data\n",
    "rf_smote_best_params = rf_gridSearchProcessor.best_params_\n",
    "\n",
    "# best model for SMOTE+ENN Data\n",
    "rf_smote_best_model = rf_gridSearchProcessor.best_estimator_\n",
    "\n",
    "# print out best parameters for SMOTE+ENN Data\n",
    "print(\"Best alpha parameter identified by grid search for SMOTE+ENN Data \", rf_smote_best_params)\n",
    "rf_smote_best_result = rf_gridSearchProcessor.best_score_\n",
    "print(\"Best result identified by grid search for SMOTE+ENN Data\", rf_smote_best_result)\n",
    "\n",
    "\n",
    "# see other parameter results\n",
    "gridsearch_results = pd.DataFrame(rf_gridSearchProcessor.cv_results_)\n",
    "gridsearch_results[['rank_test_score', 'mean_test_score',\n",
    "'params']].sort_values(by=['rank_test_score'])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9793916f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T06:48:55.499898Z",
     "start_time": "2022-08-01T06:48:54.875955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for SMOTE+ENN Data  0.680047225501771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.24      0.89      0.38       375\n",
      "    Positive       0.98      0.65      0.78      3013\n",
      "\n",
      "    accuracy                           0.68      3388\n",
      "   macro avg       0.61      0.77      0.58      3388\n",
      "weighted avg       0.90      0.68      0.74      3388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "Y_pred_smote_rf = rf_smote_best_model.predict(X_test)\n",
    "print('Accuracy Score for SMOTE+ENN Data ', accuracy_score(Y_test, Y_pred_smote_rf))\n",
    "print(classification_report(Y_test, Y_pred_smote_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26c9bba",
   "metadata": {},
   "source": [
    "## RF Hyper-parameter tuning on Training Near-miss Sampling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aaf12410",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T06:51:57.953144Z",
     "start_time": "2022-08-01T06:48:55.502863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha parameter identified by grid search for Near-miss sampling data  {'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_depth': None, 'bootstrap': False}\n",
      "Best result identified by grid search for Near-miss sampling data  0.8848394152335368\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0.884839</td>\n",
       "      <td>{'n_estimators': 300, 'min_samples_split': 10,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>0.883171</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>3</td>\n",
       "      <td>0.882509</td>\n",
       "      <td>{'n_estimators': 500, 'min_samples_split': 10,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>0.882506</td>\n",
       "      <td>{'n_estimators': 500, 'min_samples_split': 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>0.882502</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 10,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score  mean_test_score  \\\n",
       "29                1         0.884839   \n",
       "18                2         0.883171   \n",
       "67                3         0.882509   \n",
       "9                 4         0.882506   \n",
       "11                5         0.882502   \n",
       "\n",
       "                                               params  \n",
       "29  {'n_estimators': 300, 'min_samples_split': 10,...  \n",
       "18  {'n_estimators': 100, 'min_samples_split': 5, ...  \n",
       "67  {'n_estimators': 500, 'min_samples_split': 10,...  \n",
       "9   {'n_estimators': 500, 'min_samples_split': 5, ...  \n",
       "11  {'n_estimators': 100, 'min_samples_split': 10,...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random search to find best parameters\n",
    "rf_gridSearchProcessor = RandomizedSearchCV(estimator=rf,\\\n",
    "                                            param_distributions=random_grid, \n",
    "                                            cv=3, n_jobs = -1,\n",
    "                                            n_iter = 100)\n",
    "\n",
    "\n",
    "# Near-miss data\n",
    "rf_gridSearchProcessor.fit(X_train_near, Y_train_near)\n",
    "\n",
    "# best parameters for Near-miss sampling data \n",
    "rf_near_best_params = rf_gridSearchProcessor.best_params_\n",
    "\n",
    "# best model for Near-miss sampling data \n",
    "rf_near_best_model = rf_gridSearchProcessor.best_estimator_\n",
    "\n",
    "# print out best parameters for Near-miss sampling data \n",
    "print(\"Best alpha parameter identified by grid search for Near-miss sampling data \", rf_near_best_params)\n",
    "rf_near_best_result = rf_gridSearchProcessor.best_score_\n",
    "print(\"Best result identified by grid search for Near-miss sampling data \", rf_near_best_result)\n",
    "\n",
    "\n",
    "# see other parameter results\n",
    "gridsearch_results = pd.DataFrame(rf_gridSearchProcessor.cv_results_)\n",
    "gridsearch_results[['rank_test_score', 'mean_test_score',\n",
    "'params']].sort_values(by=['rank_test_score'])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f955943",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T06:51:58.342647Z",
     "start_time": "2022-08-01T06:51:57.957057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for SMOTE+ENN Data  0.6939197166469894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.25      0.88      0.39       375\n",
      "    Positive       0.98      0.67      0.80      3013\n",
      "\n",
      "    accuracy                           0.69      3388\n",
      "   macro avg       0.61      0.78      0.59      3388\n",
      "weighted avg       0.90      0.69      0.75      3388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "Y_pred_near_rf = rf_near_best_model.predict(X_test)\n",
    "print('Accuracy Score for SMOTE+ENN Data ', accuracy_score(Y_test, Y_pred_near_rf))\n",
    "print(classification_report(Y_test, Y_pred_near_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af994d7",
   "metadata": {},
   "source": [
    "## RF Hyper-parameter tuning on Training One-sided Selection Sampling Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "937dec2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T07:06:33.537031Z",
     "start_time": "2022-08-01T06:51:58.345971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha parameter identified by grid search for oss sampling data  {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None, 'bootstrap': False}\n",
      "Best result identified by grid search for oss sampling data  0.9037043196603567\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1</td>\n",
       "      <td>0.903704</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>0.901457</td>\n",
       "      <td>{'n_estimators': 300, 'min_samples_split': 10,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>0.898130</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 10,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>0.897680</td>\n",
       "      <td>{'n_estimators': 300, 'min_samples_split': 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5</td>\n",
       "      <td>0.896871</td>\n",
       "      <td>{'n_estimators': 300, 'min_samples_split': 2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score  mean_test_score  \\\n",
       "93                1         0.903704   \n",
       "37                2         0.901457   \n",
       "17                3         0.898130   \n",
       "27                4         0.897680   \n",
       "61                5         0.896871   \n",
       "\n",
       "                                               params  \n",
       "93  {'n_estimators': 100, 'min_samples_split': 5, ...  \n",
       "37  {'n_estimators': 300, 'min_samples_split': 10,...  \n",
       "17  {'n_estimators': 100, 'min_samples_split': 10,...  \n",
       "27  {'n_estimators': 300, 'min_samples_split': 2, ...  \n",
       "61  {'n_estimators': 300, 'min_samples_split': 2, ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random search to find best parameters\n",
    "rf_gridSearchProcessor = RandomizedSearchCV(estimator=rf,\\\n",
    "                                            param_distributions=random_grid, \n",
    "                                            cv=3, n_jobs = -1,\n",
    "                                            n_iter = 100)\n",
    "\n",
    "# oss data\n",
    "rf_gridSearchProcessor.fit(X_train_oss, Y_train_oss)\n",
    "\n",
    "# best parameters for oss sampling data \n",
    "rf_oss_best_params = rf_gridSearchProcessor.best_params_\n",
    "\n",
    "# best model for oss sampling data \n",
    "rf_oss_best_model = rf_gridSearchProcessor.best_estimator_\n",
    "\n",
    "# print out best parameters for oss sampling data \n",
    "print(\"Best alpha parameter identified by grid search for oss sampling data \", rf_oss_best_params)\n",
    "rf_oss_best_result = rf_gridSearchProcessor.best_score_\n",
    "print(\"Best result identified by grid search for oss sampling data \", rf_oss_best_result)\n",
    "\n",
    "\n",
    "# see other parameter results\n",
    "gridsearch_results = pd.DataFrame(rf_gridSearchProcessor.cv_results_)\n",
    "gridsearch_results[['rank_test_score', 'mean_test_score',\n",
    "'params']].sort_values(by=['rank_test_score'])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43c0cc72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T07:06:33.940507Z",
     "start_time": "2022-08-01T07:06:33.540145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for One-sided Sampling Data  0.9214876033057852\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.84      0.36      0.50       375\n",
      "    Positive       0.93      0.99      0.96      3013\n",
      "\n",
      "    accuracy                           0.92      3388\n",
      "   macro avg       0.88      0.68      0.73      3388\n",
      "weighted avg       0.92      0.92      0.91      3388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "Y_pred_oss_rf = rf_oss_best_model.predict(X_test)\n",
    "print('Accuracy Score for One-sided Sampling Data ', accuracy_score(Y_test, Y_pred_oss_rf))\n",
    "print(classification_report(Y_test, Y_pred_oss_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175c3fe6",
   "metadata": {},
   "source": [
    "# Model Comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca5dceb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T07:06:34.015395Z",
     "start_time": "2022-08-01T07:06:33.943241Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>model</th>\n",
       "      <th>parameters</th>\n",
       "      <th>accuracy score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMOTE+ENN Sampling</td>\n",
       "      <td>baseline</td>\n",
       "      <td>Most Frequent</td>\n",
       "      <td>0.110685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Near-miss Sampling</td>\n",
       "      <td>baseline</td>\n",
       "      <td>Most Frequent</td>\n",
       "      <td>0.110685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One-sided Selection Sampling Data</td>\n",
       "      <td>baseline</td>\n",
       "      <td>Most Frequent</td>\n",
       "      <td>0.889315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMOTE+ENN Sampling</td>\n",
       "      <td>SVM</td>\n",
       "      <td>{'model__C': 10, 'model__tol': 0.01}</td>\n",
       "      <td>0.755018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Near-miss Sampling</td>\n",
       "      <td>SVM</td>\n",
       "      <td>{'model__loss': 'hinge', 'model__max_iter': 10...</td>\n",
       "      <td>0.779516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>One-sided Selection Sampling Data</td>\n",
       "      <td>SVM</td>\n",
       "      <td>{'model__loss': 'hinge', 'model__max_iter': 10...</td>\n",
       "      <td>0.946871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SMOTE+ENN Sampling</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'n_estimators': 300, 'min_samples_split': 2, ...</td>\n",
       "      <td>0.680047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Near-miss Sampling</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'n_estimators': 300, 'min_samples_split': 10,...</td>\n",
       "      <td>0.693920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>One-sided Selection Sampling Data</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 5, ...</td>\n",
       "      <td>0.921488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                data          model  \\\n",
       "0                 SMOTE+ENN Sampling       baseline   \n",
       "1                 Near-miss Sampling       baseline   \n",
       "2  One-sided Selection Sampling Data       baseline   \n",
       "3                 SMOTE+ENN Sampling            SVM   \n",
       "4                 Near-miss Sampling            SVM   \n",
       "5  One-sided Selection Sampling Data            SVM   \n",
       "6                 SMOTE+ENN Sampling  Random Forest   \n",
       "7                 Near-miss Sampling  Random Forest   \n",
       "8  One-sided Selection Sampling Data  Random Forest   \n",
       "\n",
       "                                          parameters  accuracy score  \n",
       "0                                      Most Frequent        0.110685  \n",
       "1                                      Most Frequent        0.110685  \n",
       "2                                      Most Frequent        0.889315  \n",
       "3               {'model__C': 10, 'model__tol': 0.01}        0.755018  \n",
       "4  {'model__loss': 'hinge', 'model__max_iter': 10...        0.779516  \n",
       "5  {'model__loss': 'hinge', 'model__max_iter': 10...        0.946871  \n",
       "6  {'n_estimators': 300, 'min_samples_split': 2, ...        0.680047  \n",
       "7  {'n_estimators': 300, 'min_samples_split': 10,...        0.693920  \n",
       "8  {'n_estimators': 100, 'min_samples_split': 5, ...        0.921488  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## make data frame for model performance comparison\n",
    "data = ['SMOTE+ENN Sampling', 'Near-miss Sampling', 'One-sided Selection Sampling Data'] * 3\n",
    "models = ['baseline', 'baseline', 'baseline',\\\n",
    "          'SVM', 'SVM', 'SVM',\\\n",
    "         'Random Forest', 'Random Forest', 'Random Forest']\n",
    "params = ['Most Frequent', 'Most Frequent', 'Most Frequent', \\\n",
    "          smote_best_params, near_best_params, oss_best_params,\\\n",
    "         rf_smote_best_params, rf_near_best_params, rf_oss_best_params]\n",
    "performance = [accuracy_score(Y_test, Y_pred_smote_baseline), \\\n",
    "               accuracy_score(Y_test, Y_pred_near_baseline),\\\n",
    "               accuracy_score(Y_test, Y_pred_oss_baseline), \\\n",
    "               accuracy_score(Y_test, Y_pred_smote), \\\n",
    "              accuracy_score(Y_test, Y_pred_near), \\\n",
    "              accuracy_score(Y_test, Y_pred_oss), \\\n",
    "              accuracy_score(Y_test, Y_pred_smote_rf), \\\n",
    "              accuracy_score(Y_test, Y_pred_near_rf), \\\n",
    "              accuracy_score(Y_test, Y_pred_oss_rf)]\n",
    "\n",
    "model_comp = pd.DataFrame(list(zip(data, models, params, performance))) \n",
    "\n",
    "# reanming the DataFrame columns\n",
    "model_comp.rename(columns = {0:'data', \n",
    "                             1:'model',\n",
    "                             2:'parameters',\n",
    "                             3:'accuracy score'}, \n",
    "            inplace = True)\n",
    "model_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb579a69",
   "metadata": {},
   "source": [
    "# Final Model Test Unseen Data and Export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ff6a571",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T07:12:25.979211Z",
     "start_time": "2022-08-01T07:12:25.973368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Very disappointed in the Apple TV 4K. Horrible issues with audio video syncing. The audio is never in sync with the video play back . It actually moves around from a little out of sync to way out of sync. Apple support? No help at all. And Apple actually said they are only concerned with Apple designed products and don't really care abouthow another company products work with Apple TV. This appears to be a firmware issue, That Apple has no interestin addressing.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict unseen data\n",
    "unseen_data = \"Very disappointed in the Apple TV 4K. \\\n",
    "Horrible issues with audio video syncing. The audio is never in sync with the video play back . \\\n",
    "It actually moves around from a little out of sync to way out of sync. Apple support? No help at all. \\\n",
    "And Apple actually said they are only concerned with Apple designed products and don't really care about\\\n",
    "how another company products work with Apple TV. This appears to be a firmware issue, That Apple has no interest\\\n",
    "in addressing.\"\n",
    "\n",
    "unseen_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c49c3b11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T07:13:54.703586Z",
     "start_time": "2022-08-01T07:13:54.686240Z"
    }
   },
   "outputs": [],
   "source": [
    "# punctuation dictionary\n",
    "punctuation = set(punctuation) \n",
    "include_punctuation = {'’', '”', '“'}\n",
    "punctuation |= include_punctuation\n",
    "\n",
    "# stop words and other words to be excluded\n",
    "include_stopwords = {'could', 'shouldn', 'oh', 'know', 'im', 'en',\n",
    "'go', 'get', 'got', 'gonna', 'la', 'na', 'de', 'gon', 'got' 'must', 'would', 'also', \n",
    "                    'apple', 'Apple', 'Amazon', 'amazon', \n",
    "                     'roku', 'Roku', 'roku remote', 'Rokue Remote',\n",
    "                     'Google', 'google', 'chromecast', 'Chromecast', \n",
    "                    'Chrome Cast', 'chrome cast', 'chrome', 'cast'\n",
    "                     'Fire TV Stick', 'prime', 'firestick4ktv',\n",
    "                     'firestick', 'fire tv', 'fire tv stick', 'fire', \n",
    "                     'firesticks','tv', 'remote', '4k', 'stick', 'dont', \"it's\", 'tvs',\n",
    "                    'etc'}\n",
    "\n",
    "# include the dictionary of stop words\n",
    "sw |= include_stopwords\n",
    "\n",
    "# useful white space pattern\n",
    "whitespace_pattern = re.compile(r\"\\s+\")\n",
    "\n",
    "def decontracted(phrase):\n",
    "    \"\"\"\n",
    "    split up decontracted words from a column of texts\n",
    "    \n",
    "    \"\"\"\n",
    "    # add extra white space\n",
    "    phrase = re.sub('(?<=[.,!?()/:;])(?=[^\\s])', r' ',  phrase)\n",
    "   \n",
    "    # specific\n",
    "    phrase = re.sub(r\"she/her\", \"she her\",phrase)\n",
    "    phrase = re.sub(r\"he/him\", \"he him\",phrase)\n",
    "    phrase = re.sub(r\"they/them\", \"they them\",phrase)\n",
    "    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r'\\<.*\\>', '', phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    phrase = re.sub(r\"don’t\", \"do not\", phrase)\n",
    "    phrase = re.sub(r\"it's\", \"it is\", phrase)\n",
    "    phrase = re.sub(r\"it’s\", \"it is\", phrase)\n",
    "    phrase = re.sub(r\"we've\", \"we have\", phrase)\n",
    "    phrase = re.sub(\"\\w+\\d+\", \"\", phrase)\n",
    "    phrase = re.sub(\"\\d+\\w+\", \"\", phrase)\n",
    "    phrase = re.sub(\"\\d+\", \" \", phrase)\n",
    "\n",
    "    return phrase\n",
    "\n",
    "def remove_stop(tokens) :\n",
    "    \"\"\"\n",
    "    remove stop words from a column of texts\n",
    "    \"\"\"\n",
    "    \n",
    "    not_stop_words = [word for word in tokens if word not in sw]\n",
    "    return not_stop_words\n",
    " \n",
    "def remove_punctuation(text) : \n",
    "    \"\"\"\n",
    "    remove punctuation from a column of texts\n",
    "    \"\"\"\n",
    "    return(\"\".join([ch for ch in text if ch not in punctuation]))\n",
    "\n",
    "def tokenize(text) : \n",
    "    \"\"\" Splitting on whitespace\"\"\"\n",
    "    \n",
    "    # modify this function to return tokens\n",
    "    tokens = re.split(whitespace_pattern, text)\n",
    "    return(tokens)\n",
    "\n",
    "\n",
    "def remove_whitespace_token(tokens):\n",
    "    \"\"\" Remove whitespace tokens\"\"\"\n",
    "    \n",
    "    # loop through each token to find whitespace token and remove\n",
    "    for i in tokens:\n",
    "        if '' in tokens:\n",
    "            tokens.remove('')\n",
    "    return tokens\n",
    "\n",
    "def prepare(text, pipeline) :\n",
    "    \"\"\"\n",
    "    prepare function applies each cleaning transformation\n",
    "    function onto a column of text\n",
    "    \"\"\"\n",
    "    tokens = str(text)\n",
    "    \n",
    "    for transform in pipeline : \n",
    "        tokens = transform(tokens)\n",
    "        \n",
    "    return(tokens)\n",
    "\n",
    "\n",
    "# list of cleaning functions\n",
    "pipeline = [str.lower, decontracted, remove_punctuation, tokenize, remove_whitespace_token, remove_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e263739",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T07:14:06.069184Z",
     "start_time": "2022-08-01T07:14:06.057244Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pre-process amazon review\n",
    "review = pd.DataFrame([unseen_data], columns=['review_text'])\n",
    "    \n",
    "# Start with one review:\n",
    "text = review.review_text[0]\n",
    "\n",
    "# pre-processing pipeline\n",
    "review['clean_reviews'] = review['review_text'].apply(prepare,pipeline= pipeline)\n",
    "    \n",
    "# remove any unicode characters\n",
    "review['clean_reviews'].replace({r'[^\\x00-\\x7F]+':''}, regex=True, inplace=True)\n",
    "\n",
    "# drop original reviews column\n",
    "review.drop(columns = ['review_text'], axis = 1, inplace = True)\n",
    "\n",
    "# untokenize plot descriptions\n",
    "review['clean_reviews'] = review['clean_reviews'].apply(lambda x: TreebankWordDetokenizer().detokenize(x))\n",
    "\n",
    "review = tfidf.transform(review['clean_reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04fc1363",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T07:14:43.857128Z",
     "start_time": "2022-08-01T07:14:43.781565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Negative']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.989</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Negative  Positive\n",
       "0     0.989     0.011"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM OSS final model\n",
    "final_svm_model = oss_best_model\n",
    "\n",
    "# probabilities/likelihood set up\n",
    "final_svm_model_proba = CalibratedClassifierCV(final_svm_model, cv='prefit') \n",
    "final_svm_model_proba.fit(X_train_oss, Y_train_oss)\n",
    "\n",
    "# put probabilities into data frame\n",
    "pred_class = final_svm_model_proba.predict(review)\n",
    "print(pred_class)\n",
    "pd.DataFrame(np.round(final_svm_model_proba.predict_proba(review),3),\\\n",
    "             columns=final_svm_model_proba.classes_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3177dbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T07:15:08.565092Z",
     "start_time": "2022-08-01T07:15:08.549513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_svm_model.pkl']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final model export - svm oss \n",
    "joblib.dump(final_svm_model_proba, 'final_svm_model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4fdc1b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T07:15:41.455647Z",
     "start_time": "2022-08-01T07:15:40.717596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.465</td>\n",
       "      <td>0.535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Negative  Positive\n",
       "0     0.465     0.535"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RF OSS final model\n",
    "final_rf_model = rf_oss_best_model\n",
    "\n",
    "# probabilities/likelihood set up\n",
    "final_rf_model_proba = CalibratedClassifierCV(final_rf_model, cv='prefit') \n",
    "final_rf_model_proba.fit(X_train_oss, Y_train_oss)\n",
    "\n",
    "# put probabilities into data frame\n",
    "pred_class = final_rf_model_proba.predict(review)\n",
    "print(pred_class)\n",
    "pd.DataFrame(np.round(final_rf_model_proba.predict_proba(review),3),\\\n",
    "             columns=final_rf_model_proba.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "409bc317",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T07:15:46.916241Z",
     "start_time": "2022-08-01T07:15:46.550519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_rf_model.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final model export - rf oss\n",
    "joblib.dump(final_rf_model_proba, 'final_rf_model.pkl') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ads599] *",
   "language": "python",
   "name": "conda-env-ads599-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
